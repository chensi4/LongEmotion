import os
import torch
import pandas as pd
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from collections import Counter

DATA_PATH = r"english_emotion_fragments.csv"
LABEL2EMOTION = {0: "negative", 1: "positive"}
MODEL_NAME = "distilbert-base-uncased-finetuned-sst-2-english"
MAX_LENGTH = 512
BATCH_SIZE = 8
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"âœ… ä½¿ç”¨è®¾å¤‡: {device} | è‹±æ–‡æ¨¡åž‹: {MODEL_NAME}")

def load_english_fragments(data_path):
    if not os.path.exists(data_path):
        raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼š{data_path}")
    
    df = pd.read_csv(data_path, encoding="utf-8").reset_index(drop=True)
    required_cols = ["id", "text"]
    if not all(col in df.columns for col in required_cols):
        raise ValueError(f"âŒ æ•°æ®æ–‡ä»¶éœ€åŒ…å«åˆ—ï¼š{required_cols}")
    
    df = df.dropna(subset=["text"]).drop_duplicates(subset=["text"])
    df["text"] = df["text"].str.strip()
    df = df[df["text"].str.len() > 1]
    
    n = len(df)
    if n < 2:
        raise ValueError(f"âŒ æ–‡æœ¬ç‰‡æ®µæ•°é‡éœ€â‰¥2ï¼ˆå½“å‰n={n}ï¼‰")
    
    print(f"âœ… åŠ è½½å®Œæˆï¼šå…± {n} ä¸ªè‹±æ–‡æ–‡æœ¬ç‰‡æ®µï¼ˆidèŒƒå›´ï¼š{df['id'].min()}~{df['id'].max()}ï¼‰")
    return df

def load_english_emotion_llm(model_name):
    print(f"\nðŸ”„ åŠ è½½è‹±æ–‡LLMæ¨¡åž‹ï¼š{model_name}...")
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)
    model.eval()
    print(f"âœ… è‹±æ–‡LLMæ¨¡åž‹åŠ è½½å®Œæˆï¼ˆè¾“å‡ºæ ‡ç­¾æ•°ï¼š{model.num_labels}ï¼‰")
    return tokenizer, model

def predict_english_emotion_batch(tokenizer, model, texts, batch_size=BATCH_SIZE):
    all_preds = []
    for i in range(0, len(texts), batch_size):
        batch_texts = texts[i:i+batch_size]
        inputs = tokenizer(
            batch_texts,
            max_length=MAX_LENGTH,
            padding="max_length",
            truncation=True,
            return_tensors="pt"
        ).to(device)
        
        with torch.no_grad():
            outputs = model(** inputs)
            preds = torch.argmax(outputs.logits, dim=-1).cpu().numpy()
            all_preds.extend(preds.tolist())
    
    all_emotions = [LABEL2EMOTION[pred] for pred in all_preds]
    return all_emotions

def find_unique_emotion_fragment(df_with_emotion):
    emotion_counter = Counter(df_with_emotion["predicted_emotion"])
    print(f"\nðŸ“Š æƒ…æ„Ÿé¢‘æ¬¡ç»Ÿè®¡ï¼š{dict(emotion_counter)}")
    
    if len(emotion_counter) != 2:
        raise ValueError(f"âŒ æƒ…æ„Ÿç±»åˆ«æ•°é‡â‰ 2ï¼ˆå½“å‰{len(emotion_counter)}ç±»ï¼‰ï¼Œä¸ç¬¦åˆè§„åˆ™")
    
    unique_emotion = None
    common_emotion = None
    for emotion, count in emotion_counter.items():
        if count == 1:
            unique_emotion = emotion
        else:
            common_emotion = emotion
    
    if unique_emotion is None:
        raise ValueError(f"âŒ æœªæ‰¾åˆ°é¢‘æ¬¡ä¸º1çš„ç‹¬ç‰¹æƒ…æ„Ÿï¼ˆå½“å‰é¢‘æ¬¡ï¼š{dict(emotion_counter)}ï¼‰")
    
    unique_fragment = df_with_emotion[df_with_emotion["predicted_emotion"] == unique_emotion]
    print(f"\nðŸŽ‰ ç‹¬ç‰¹æƒ…æ„Ÿå®šä½ç»“æžœï¼š")
    print(f"   - å…±åŒæƒ…æ„Ÿï¼š{common_emotion}ï¼ˆå…±{emotion_counter[common_emotion]}ä¸ªç‰‡æ®µï¼‰")
    print(f"   - ç‹¬ç‰¹æƒ…æ„Ÿï¼š{unique_emotion}ï¼ˆå…±1ä¸ªç‰‡æ®µï¼‰")
    print(f"   - ç‹¬ç‰¹ç‰‡æ®µIDï¼š{unique_fragment['id'].iloc[0]}")
    print(f"   - ç‹¬ç‰¹ç‰‡æ®µæ–‡æœ¬ï¼š{unique_fragment['text'].iloc[0][:100]}...")
    
    return unique_fragment, unique_emotion, common_emotion

def main():
    try:
        df = load_english_fragments(DATA_PATH)
        tokenizer, model = load_english_emotion_llm(MODEL_NAME)
        print(f"\nðŸš€ å¼€å§‹æ‰¹é‡æƒ…æ„Ÿåˆ†ç±»ï¼ˆå…±{len(df)}ä¸ªç‰‡æ®µï¼Œæ‰¹æ¬¡å¤§å°ï¼š{BATCH_SIZE}ï¼‰...")
        df["predicted_emotion"] = predict_english_emotion_batch(tokenizer, model, df["text"].tolist())
        print("âœ… æƒ…æ„Ÿåˆ†ç±»å®Œæˆï¼")
        unique_fragment, unique_emotion, common_emotion = find_unique_emotion_fragment(df)
        result_save_path = "english_unique_emotion_result.csv"
        df.to_csv(result_save_path, encoding="utf-8", index=False)
        print(f"\nðŸ’¾ ç»“æžœå·²ä¿å­˜è‡³ï¼š{os.path.abspath(result_save_path)}")
    
    except Exception as e:
        print(f"\nâŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥ï¼š{str(e)}")

if __name__ == "__main__":
    main()
